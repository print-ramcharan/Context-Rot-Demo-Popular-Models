chunking:
  chunk_size: 200
  overlap: 50

embedding:
  model_name: "all-MiniLM-L6-v2"
  device: "cpu"

retrieval:
  top_k: 5
  similarity_threshold: 0.1

llm:
  provider: "gemini"  # Options: "ollama", "huggingface", "anthropic", "openai", "gemini"
  
  # For Ollama (local, no API key needed)
  ollama:
    model: "llama2"  # or "mistral", "phi", "gemma"
    base_url: "http://localhost:11434"
  
  # For HuggingFace (local, no API key needed)
  huggingface:
    model: "mistralai/Mistral-7B-Instruct-v0.2"
    device: "cpu"  # or "cuda" if GPU available
    load_in_8bit: false
  
  # For API-based models (requires API key)
  anthropic:
    model: "claude-sonnet-4-20250514"
    api_key: ""  # Set via environment variable
  
  openai:
    model: "gpt-4"
    api_key: ""  # Set via environment variable
  
  # For Gemini (requires API key)
  gemini:
    model: "gemma-3-27b-it"
    api_key: ""
  
  # Common parameters
  max_tokens: 1000
  temperature: 0.7
